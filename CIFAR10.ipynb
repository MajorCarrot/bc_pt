{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcec64bc-3d95-454c-ac63-5ce014cc6bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from BinaryLayers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2248b06f-6380-47df-9062-60b011cc0154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Binary Layers\n",
    "H = 1\n",
    "deterministic = True\n",
    "\n",
    "# For Training\n",
    "batch_size = 50\n",
    "num_epochs = 500\n",
    "\n",
    "# For batchnorm\n",
    "epsilon = 1e-4\n",
    "alpha = .1\n",
    "\n",
    "# For the optimizer\n",
    "lr = .003\n",
    "\n",
    "# Set GPU\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce463854-5458-4776-acc0-b4234922605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn(Module):\n",
    "    def __init__(self):\n",
    "        super(nn, self).__init__()\n",
    "\n",
    "        self.c3_128_1 = BinaryConv2D(3, 128, 3, padding=1, H=H, deterministic=deterministic)\n",
    "        self.bn_1 = torch.nn.BatchNorm2d(128, eps=epsilon, momentum=alpha)\n",
    "\n",
    "        self.c3_128_2 = BinaryConv2D(128, 128, 3, padding=1, H=H, deterministic=deterministic)\n",
    "        self.mp2_2 = torch.nn.MaxPool2d(2)\n",
    "        self.bn_2 = torch.nn.BatchNorm2d(128, eps=epsilon, momentum=alpha)\n",
    "\n",
    "        self.c3_256_3 = BinaryConv2D(128, 256, 3, padding=1, H=H, deterministic=deterministic)\n",
    "        self.bn_3 = torch.nn.BatchNorm2d(256, eps=epsilon, momentum=alpha)\n",
    "\n",
    "        self.c3_256_4 = BinaryConv2D(256, 256, 3, padding=1, H=H, deterministic=deterministic)\n",
    "        self.mp2_4 = torch.nn.MaxPool2d(2)\n",
    "        self.bn_4 = torch.nn.BatchNorm2d(256, eps=epsilon, momentum=alpha)\n",
    "\n",
    "        self.c3_512_5 = BinaryConv2D(256, 512, 3, padding=1, H=H, deterministic=deterministic)\n",
    "        self.bn_5 = torch.nn.BatchNorm2d(512, eps=epsilon, momentum=alpha)\n",
    "\n",
    "        self.c3_512_6 = BinaryConv2D(512, 512, 3, padding=1, H=H, deterministic=deterministic)\n",
    "        self.mp2_6 = torch.nn.MaxPool2d(2)\n",
    "        self.bn_6 = torch.nn.BatchNorm2d(512, eps=epsilon, momentum=alpha)\n",
    "\n",
    "        self.d_1024_7 = BinaryDense(2048 * 4, 1024, H=H, deterministic=deterministic)\n",
    "        self.bn_7 = torch.nn.BatchNorm1d(1024, eps=epsilon, momentum=alpha)\n",
    "        \n",
    "        self.d_1024_8 = BinaryDense(1024, 1024, H=H, deterministic=deterministic)\n",
    "        self.bn_8 = torch.nn.BatchNorm1d(1024, eps=epsilon, momentum=alpha)\n",
    "\n",
    "        self.d_10_9 = BinaryDense(1024, 10, H=H, deterministic=deterministic)\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.c3_128_1(input)\n",
    "        x = torch.nn.ReLU()(self.bn_1(x))\n",
    "#         print(x.shape)\n",
    "        x = self.c3_128_2(x)\n",
    "        x = self.mp2_2(x)\n",
    "        x = torch.nn.ReLU()(self.bn_2(x))\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = self.c3_256_3(x)\n",
    "        x = torch.nn.ReLU()(self.bn_3(x))\n",
    "#         print(x.shape)\n",
    "        x = self.c3_256_4(x)\n",
    "        x = self.mp2_4(x)\n",
    "        x = torch.nn.ReLU()(self.bn_4(x))\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = self.c3_512_5(x)\n",
    "        x = torch.nn.ReLU()(self.bn_5(x))\n",
    "#         print(x.shape)\n",
    "        x = self.c3_512_6(x)\n",
    "        x = self.mp2_6(x)\n",
    "        x = torch.nn.ReLU()(self.bn_6(x))\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = torch.nn.Flatten()(x)\n",
    "        \n",
    "        x = self.d_1024_7(x)\n",
    "        x = torch.nn.ReLU()(self.bn_7(x))\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = self.d_1024_8(x)\n",
    "        x = torch.nn.ReLU()(self.bn_8(x))\n",
    "#         print(x.shape)\n",
    "\n",
    "        x = self.d_10_9(x)\n",
    "        x = torch.nn.Softmax(-1)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "361563b3-61f6-45f7-9c05-f67d0a8dd8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "225376c1-d7d5-40ca-bef4-e649a4f0f7ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nn(\n",
       "  (c3_128_1): BinaryConv2D(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_1): BatchNorm2d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c3_128_2): BinaryConv2D(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (mp2_2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bn_2): BatchNorm2d(128, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c3_256_3): BinaryConv2D(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_3): BatchNorm2d(256, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c3_256_4): BinaryConv2D(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (mp2_4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bn_4): BatchNorm2d(256, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c3_512_5): BinaryConv2D(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn_5): BatchNorm2d(512, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (c3_512_6): BinaryConv2D(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (mp2_6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (bn_6): BatchNorm2d(512, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_1024_7): BinaryDense(in_features=8192, out_features=1024, bias=False)\n",
       "  (bn_7): BatchNorm1d(1024, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_1024_8): BinaryDense(in_features=1024, out_features=1024, bias=False)\n",
       "  (bn_8): BatchNorm1d(1024, eps=0.0001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (d_10_9): BinaryDense(in_features=1024, out_features=10, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12819563-1100-4938-9e51-1f7ba854003e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "t = transforms.Compose(\n",
    "    [\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean=(0), std=(1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    torchvision.datasets.CIFAR10(\n",
    "        \"/data/cifar\",\n",
    "        download=True,\n",
    "        train=True,\n",
    "        transform=t,\n",
    "        target_transform=torchvision.transforms.Compose([\n",
    "            lambda x:torch.LongTensor([x]), # or just torch.tensor\n",
    "            lambda x:torch.nn.functional.one_hot(x, 10)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "dl_test = DataLoader(\n",
    "    torchvision.datasets.CIFAR10(\n",
    "        \"/data/cifar\",\n",
    "        download=True,\n",
    "        train=False,\n",
    "        transform=t,\n",
    "        target_transform=torchvision.transforms.Compose([\n",
    "            lambda x:torch.LongTensor([x]), # or just torch.tensor\n",
    "            lambda x:torch.nn.functional.one_hot(x, 10)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5d810614-fc5c-4902-9c03-0564d613f47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = SquareHingeLoss\n",
    "# loss = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24cf9650-8320-43da-b83e-b8e9d972f783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs, dl_train, dl_valid, optimizer, lossfunction):\n",
    "    losses = [0] * num_epochs\n",
    "    val_losses = [0] * num_epochs\n",
    "    total_steps = len(dl_train) * num_epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}\")\n",
    "        # Start training\n",
    "        model.train()\n",
    "        for i, (input, target) in enumerate(dl_train):\n",
    "            optimizer.zero_grad()\n",
    "#             input = torch.reshape(input, (-1, 32 * 32)).to(device)\n",
    "            input = input.to(device)\n",
    "            target = torch.reshape(target, (-1, 10)).to(device)\n",
    "            output = model(input)\n",
    "\n",
    "            loss = lossfunction(output, target.float())\n",
    "            losses[epoch] += loss.item()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print(i + 1, \"{:.04}\".format(losses[epoch] / (i + 1)), end=\"\\t\")\n",
    "            \n",
    "        model.eval()\n",
    "        tot_acc = 0\n",
    "        with torch.no_grad():\n",
    "            for j, (input, target) in enumerate(dl_valid):\n",
    "#                 input = torch.reshape(input, (-1, 32 * 32)).to(device)\n",
    "                input = input.to(device)\n",
    "                target = target.reshape((-1, 10)).to(device)\n",
    "                output = model(input)\n",
    "                loss = lossfunction(output, target.float())\n",
    "                val_losses[epoch] += loss.item()\n",
    "                tot_acc = (tot_acc * j + int(sum(torch.argmax(target, -1) == torch.argmax(output, -1))) / len(target)) / (j + 1)\n",
    "        print(\"\")\n",
    "        print(\"Epoch training loss\" , losses[epoch] / len(dl_train))\n",
    "        print(\"Epoch valid loss\" , val_losses[epoch] / len(dl_valid))\n",
    "        print(\"Validation Accuracy:\", tot_acc)\n",
    "    return losses, val_losses,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed7ad05e-7054-4379-869c-ae9cdf6429e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "10 0.247\t20 0.2471\t30 0.247\t40 0.2471\t50 0.2469\t60 0.2469\t70 0.247\t80 0.2469\t90 0.2469\t100 0.2469\t110 0.2469\t120 0.2469\t130 0.2469\t140 0.2469\t150 0.2469\t160 0.2469\t170 0.2469\t180 0.2469\t190 0.247\t200 0.247\t210 0.247\t220 0.247\t230 0.247\t240 0.247\t250 0.2471\t260 0.2471\t270 0.2471\t280 0.2471\t290 0.2471\t300 0.2471\t310 0.2472\t320 0.2471\t330 0.2472\t340 0.2472\t350 0.2471\t360 0.2472\t370 0.2472\t380 0.2472\t390 0.2472\t400 0.2472\t410 0.2472\t420 0.2472\t430 0.2472\t440 0.2472\t450 0.2472\t460 0.2472\t470 0.2472\t480 0.2472\t490 0.2472\t"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-7b6a1dbc5440>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-7d587c61f4e2>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, num_epochs, dl_train, dl_valid, optimizer, lossfunction)\u001b[0m\n\u001b[0;32m     12\u001b[0m             \u001b[0minput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m             \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Adithya\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a58c879fe2fe>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;31m#         print(x.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc3_256_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmp2_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn_4\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Adithya\\Anaconda3\\envs\\torchenv\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Adithya\\dev\\MITACS\\bc_pt\\BinaryLayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 215\u001b[1;33m         \u001b[0mweight_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    216\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Adithya\\dev\\MITACS\\bc_pt\\BinaryLayers.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(ctx, weight, H, deterministic)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mweight_binary\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhard_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Adithya\\dev\\MITACS\\bc_pt\\BinaryLayers.py\u001b[0m in \u001b[0;36mhard_sigmoid\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mhard_sigmoid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mBinarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, num_epochs, dl_train, dl_test, optimizer, loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2899a-2c07-482d-9c21-ad0674462430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d26cabe-d76e-40c7-9d32-583deca78eea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
