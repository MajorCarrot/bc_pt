{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5920610e-189c-4a96-9262-97da8d4e1458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch import Tensor\n",
    "from torch.autograd import Function\n",
    "from torch.nn import init, Module\n",
    "from torch.nn.parameter import Parameter, UninitializedParameter\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from typing import Optional, Tuple, List, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ca2c856d-4cb4-4dbc-8b45-568374b4bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hard_sigmoid(x: Tensor):\n",
    "    return torch.clip((x + 1) / 2, 0, 1)\n",
    "\n",
    "def binarize(weight: Tensor, H: float, deterministic: bool=True) -> Tensor:\n",
    "    weight_binary = hard_sigmoid(weight / H)\n",
    "    \n",
    "    if deterministic:\n",
    "        weight_binary = torch.round(weight_binary)\n",
    "    else:\n",
    "        weight_binary = torch.bernoulli(weight_binary)\n",
    "#         print(weight_binary.is_cuda)\n",
    "        weight_binary = weight_binary.float()\n",
    "    \n",
    "    weight_binary = ((2 * weight_binary - 1) * H).float()\n",
    "#     weight_binary = weight\n",
    "    return weight_binary\n",
    "\n",
    "\n",
    "class BinaryLinearFunction(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input: Tensor, weight: Tensor, bias: Tensor=None, H: float=1., deterministic: bool=True):\n",
    "        # Binarize the weights for forward prop\n",
    "        weight_binary = binarize(weight, H, deterministic)\n",
    "        \n",
    "        # The full precision weights are required for backprop\n",
    "        ctx.save_for_backward(input, weight_binary, bias)\n",
    "#         print(input.shape, weight_binary.shape)\n",
    "        \n",
    "        output = torch.mm(input, weight_binary.t())\n",
    "        if bias is not None:\n",
    "            output += bias.unsqueeze(0).expand_as(output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: Tensor):\n",
    "        input, weight_binary, bias = ctx.saved_tensors\n",
    "        grad_input = grad_weight = grad_bias = None\n",
    "        \n",
    "        if ctx.needs_input_grad[0]:\n",
    "            grad_input = torch.mm(grad_output, weight_binary)\n",
    "            \n",
    "        if ctx.needs_input_grad[1]:\n",
    "            grad_weight = torch.mm(grad_output.t(), input)\n",
    "            \n",
    "        if bias is not None and ctx.needs_input_grad[2]:\n",
    "            grad_bias = grad_output.sum(0)\n",
    "            \n",
    "        return grad_input, grad_weight, grad_bias, None, None\n",
    "\n",
    "binary_linear = BinaryLinearFunction.apply\n",
    "    \n",
    "class BinaryDense(Module):\n",
    "    __constants__ = [\"in_features\", \"out_features\"]\n",
    "    in_features: int\n",
    "    out_features: int\n",
    "    weight: Tensor\n",
    "    binary_weight: Tensor\n",
    "\n",
    "    def __init__(self, in_features: int, out_features: int, H: float=1, bias: bool=False, deterministic: bool=True) -> None:\n",
    "        super(BinaryDense, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.weight = Parameter(Tensor(out_features, in_features))\n",
    "        self.H = H\n",
    "        if bias:\n",
    "            self.bias = Parameter(Tensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "        self.deterministic = deterministic\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            init.zeros_(self.bias)\n",
    "            \n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return binary_linear(input, self.weight, self.bias, self.H, self.deterministic)\n",
    "\n",
    "    def extra_repr(self) -> str:\n",
    "        return 'in_features={}, out_features={}, bias={}'.format(\n",
    "            self.in_features, self.out_features, self.bias is not None\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5778125-2850-4cdf-97a5-0b15e03c89b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6745253d-37dc-4030-940f-2519aea0507d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.1479529457915033\n",
      "Epoch valid loss 0.1235754980872839\n",
      "Epoch 2\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.1002253546880988\n",
      "Epoch valid loss 0.07413571523741269\n",
      "Epoch 3\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.059664154313823096\n",
      "Epoch valid loss 0.046792120433961734\n",
      "Epoch 4\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.042854072920118384\n",
      "Epoch valid loss 0.0376295824893392\n",
      "Epoch 5\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.035424718868114755\n",
      "Epoch valid loss 0.03174575439725931\n",
      "Epoch 6\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.03128539063991644\n",
      "Epoch valid loss 0.028606332289293792\n",
      "Epoch 7\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.02870556405490726\n",
      "Epoch valid loss 0.02648879523174121\n",
      "Epoch 8\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.026635074002954822\n",
      "Epoch valid loss 0.024715889149751417\n",
      "Epoch 9\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.02543792919988115\n",
      "Epoch valid loss 0.024047060511433162\n",
      "Epoch 10\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.024643645383035526\n",
      "Epoch valid loss 0.022838720084669497\n",
      "Epoch 11\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.023580507283759676\n",
      "Epoch valid loss 0.02194063099196706\n",
      "Epoch 12\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.022908654830092166\n",
      "Epoch valid loss 0.022505139370854847\n",
      "Epoch 13\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.02244342191136864\n",
      "Epoch valid loss 0.020643592382279728\n",
      "Epoch 14\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.021806224850285\n",
      "Epoch valid loss 0.020848925261256788\n",
      "Epoch 15\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.02115484170265432\n",
      "Epoch valid loss 0.020258038734587338\n",
      "Epoch 16\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.020553390340258677\n",
      "Epoch valid loss 0.019299008776075564\n",
      "Epoch 17\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.020198719936192162\n",
      "Epoch valid loss 0.019061396985004347\n",
      "Epoch 18\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.02001202482188869\n",
      "Epoch valid loss 0.01937027889279983\n",
      "Epoch 19\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.01970009838676669\n",
      "Epoch valid loss 0.018806109682489663\n",
      "Epoch 20\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.01952961238168785\n",
      "Epoch valid loss 0.018795932022233803\n",
      "Epoch 21\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.01921143481392477\n",
      "Epoch valid loss 0.018370170361147478\n",
      "Epoch 22\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.018904393596542824\n",
      "Epoch valid loss 0.01821938776769317\n",
      "Epoch 23\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.018626757668585986\n",
      "Epoch valid loss 0.01807939595518968\n",
      "Epoch 24\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.01830085955806968\n",
      "Epoch valid loss 0.01767052301707176\n",
      "Epoch 25\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.018099886641845617\n",
      "Epoch valid loss 0.017039322348024983\n",
      "Epoch 26\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.01810447967802294\n",
      "Epoch valid loss 0.018102678494193614\n",
      "Epoch 27\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.01782915390068745\n",
      "Epoch valid loss 0.01742746409936211\n",
      "Epoch 28\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.017520513796470422\n",
      "Epoch valid loss 0.016833302051497575\n",
      "Epoch 29\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.017136953244757894\n",
      "Epoch valid loss 0.01677053233083242\n",
      "Epoch 30\n",
      "0 10 20 30 40 50 60 70 80 90 100 110 120 130 140 150 160 170 180 190 200 210 220 230 240 250 260 270 280 290 300 310 320 330 340 350 360 370 380 390 400 410 420 430 440 450 460 \n",
      "Epoch training loss 0.01713647770607828\n",
      "Epoch valid loss 0.016473534958771407\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "alpha = .15\n",
    "epsilon = 1e-4\n",
    "num_units = 100\n",
    "n_hidden_layers = 1\n",
    "num_epochs = 30\n",
    "dropout_in = 0\n",
    "dropout_hidden = 0\n",
    "\n",
    "deterministic = False\n",
    "H = 1.\n",
    "\n",
    "learning_rate = .001\n",
    "min_learning_rate = 3e-6\n",
    "decay = (learning_rate - min_learning_rate) / num_epochs\n",
    "\n",
    "t = transforms.Compose(\n",
    "    [\n",
    "       transforms.ToTensor(),\n",
    "       transforms.Normalize(mean=(0), std=(1))\n",
    "    ]\n",
    ")\n",
    "\n",
    "dl_train = DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        \"/data/mnist\",\n",
    "        download=True,\n",
    "        train=True,\n",
    "        transform=t,\n",
    "        target_transform=torchvision.transforms.Compose([\n",
    "            lambda x:torch.LongTensor([x]), # or just torch.tensor\n",
    "            lambda x:torch.nn.functional.one_hot(x, 10)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "dl_valid = DataLoader(\n",
    "    torchvision.datasets.MNIST(\n",
    "        \"/data/mnist\",\n",
    "        download=True,\n",
    "        train=False,\n",
    "        transform=t,\n",
    "        target_transform=torchvision.transforms.Compose([\n",
    "            lambda x:torch.LongTensor([x]), # or just torch.tensor\n",
    "            lambda x:torch.nn.functional.one_hot(x, 10)\n",
    "        ])\n",
    "    ),\n",
    "    batch_size=batch_size,\n",
    "    drop_last=True,\n",
    "    shuffle=True\n",
    ")\n",
    "num_in = 28 * 28\n",
    "\n",
    "layers = []\n",
    "layers.append(torch.nn.Dropout(dropout_in))\n",
    "for i in range(n_hidden_layers):\n",
    "    layers.append(BinaryDense(num_in, num_units, H=H, deterministic=deterministic))\n",
    "#     layers.append(torch.nn.BatchNorm1d(num_units))\n",
    "#     layers.append(torch.nn.Linear(num_in, num_units))\n",
    "    layers.append(torch.nn.Sigmoid())\n",
    "#     layers.append(torch.nn.Dropout(dropout_hidden))\n",
    "    num_in = num_units\n",
    "# layers.append(torch.nn.Linear(num_in, 10))\n",
    "layers.append(BinaryDense(num_in, 10, H=H, deterministic=deterministic))\n",
    "# layers.append(torch.nn.BatchNorm1d(10, eps=epsilon, momentum=alpha))\n",
    "layers.append(torch.nn.Softmax(1))\n",
    "model = torch.nn.Sequential(*layers).to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=30)\n",
    "lossfunction = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "losses = [0] * num_epochs\n",
    "val_losses = [0] * num_epochs\n",
    "total_steps = len(dl_train) * num_epochs\n",
    "\n",
    "# from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}\")\n",
    "    model.train()\n",
    "    ect = 0\n",
    "    ecv = 0\n",
    "    ett = 0\n",
    "    etv = 0\n",
    "    for i, (input, target) in enumerate(dl_train):\n",
    "        if i % 10 == 0:\n",
    "            print(i, end=\" \")\n",
    "        optimizer.zero_grad()\n",
    "        input = torch.reshape(input, (-1, 28 * 28)).to(device)\n",
    "        target = torch.reshape(target, (-1, 10)).to(device)\n",
    "        \n",
    "        output = model(input)\n",
    "#         ect += accuracy_score(output.argmax(dim=-1).cpu(), target.argmax(dim=-1).cpu(), normalize=False)\n",
    "        \n",
    "#         print(output.shape, target.shape)\n",
    "        \n",
    "        loss = lossfunction(output, target.float())\n",
    "        losses[epoch] += loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "#         scheduler.step()\n",
    "#         ett += target.shape[0]\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for j, (input, target) in enumerate(dl_valid):\n",
    "            input = torch.reshape(input, (-1, 28*28)).to(device)\n",
    "            target = target.reshape((-1, 10)).to(device)\n",
    "            output = model(input)\n",
    "            loss = lossfunction(output, target.float())\n",
    "            val_losses[epoch] += loss.item()\n",
    "#             ecv += accuracy_score(output.argmax(dim=-1).cpu(), target.argmax(dim=-1).cpu(), normalize=False)\n",
    "#             etv += target.shape[0]\n",
    "    \n",
    "    print(\"\")\n",
    "    print(\"Epoch training loss\" , losses[epoch] / len(dl_train))\n",
    "    print(\"Epoch valid loss\" , val_losses[epoch] / len(dl_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "da8a7597-af14-4947-8bf2-5b4419fc4afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.8928285256410257\n"
     ]
    }
   ],
   "source": [
    "tot_acc = 0\n",
    "with torch.no_grad():\n",
    "    for j, (input, target) in enumerate(dl_valid):\n",
    "        input = torch.reshape(input, (-1, 28*28)).to(device)\n",
    "        target = target.to(device)\n",
    "        output = model(input)\n",
    "        target = target.argmax(-1).reshape(-1)\n",
    "        output = output.argmax(-1).reshape(-1)\n",
    "        \n",
    "        tot_acc = (tot_acc * j + int(sum(target == output)) / len(target)) / (j + 1)\n",
    "\n",
    "print(\"Validation Accuracy:\", tot_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc723e68-aadd-4872-953a-4fd086b284c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347b21d3-cbe3-469f-beab-733c6577a1fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8b7f9-57be-4dab-9943-8a0985ff0671",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _BinaryConvNd(Module):\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]) -> Tensor:\n",
    "        ...\n",
    "\n",
    "    _in_channels: int\n",
    "    _reversed_padding_repeated_twice: List[int]\n",
    "    out_channels: int\n",
    "    kernel_size: Tuple[int, ...]\n",
    "    stride: Tuple[int, ...]\n",
    "    padding: Union[str, Tuple[int, ...]]\n",
    "    dilation: Tuple[int, ...]\n",
    "    transposed: bool\n",
    "    output_padding: Tuple[int, ...]\n",
    "    groups: int\n",
    "    padding_mode: str\n",
    "    weight: Tensor\n",
    "    bias: Optional[Tensor]\n",
    "\n",
    "\n",
    "    def __init__(self,\n",
    "                 in_channels: int,\n",
    "                 out_channels: int,\n",
    "                 kernel_size: Tuple[int, ...],\n",
    "                 stride: Tuple[int, ...],\n",
    "                 padding: Tuple[int, ...],\n",
    "                 dilation: Tuple[int, ...],\n",
    "                 transposed: bool,\n",
    "                 output_padding: Tuple[int, ...],\n",
    "                 groups: int,\n",
    "                 bias: bool,\n",
    "                 padding_mode: str,\n",
    "                 H: float=1.,\n",
    "                 deterministic: bool=True) -> None:\n",
    "        super(BinaryConvNd, self).__init__()\n",
    "        \n",
    "        if in_channels % groups != 0:\n",
    "            raise ValueError('in_channels must be divisible by groups')\n",
    "        if out_channels % groups != 0:\n",
    "            raise ValueError('out_channels must be divisible by groups')\n",
    "        valid_padding_modes = {'zeros', 'reflect', 'replicate', 'circular'}\n",
    "        if padding_mode not in valid_padding_modes:\n",
    "            raise ValueError(\"padding_mode must be one of {}, but got padding_mode='{}'\".format(\n",
    "                valid_padding_modes, padding_mode))\n",
    "\n",
    "        self.H = H\n",
    "        self.deterministic = deterministic\n",
    "        \n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "        self.dilation = dilation\n",
    "        self.transposed = transposed\n",
    "        self.output_padding = output_padding\n",
    "        self.groups = groups\n",
    "        self.padding_mode = padding_mode\n",
    "        # `_reversed_padding_repeated_twice` is the padding to be passed to\n",
    "        # `F.pad` if needed (e.g., for non-zero padding types that are\n",
    "        # implemented as two ops: padding + conv). `F.pad` accepts paddings in\n",
    "        # reverse order than the dimension.\n",
    "        self._reversed_padding_repeated_twice = _reverse_repeat_tuple(self.padding, 2)\n",
    "        if transposed:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                in_channels, out_channels // groups, *kernel_size))\n",
    "        else:\n",
    "            self.weight = Parameter(torch.Tensor(\n",
    "                out_channels, in_channels // groups, *kernel_size))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self) -> None:\n",
    "        init.xavier_uniform_(self.weight)\n",
    "        if self.bias is not None:\n",
    "            init.xavier_uniform_(self.bias)\n",
    "\n",
    "    def extra_repr(self):\n",
    "        s = ('{in_channels}, {out_channels}, kernel_size={kernel_size}'\n",
    "             ', stride={stride}')\n",
    "        if self.padding != (0,) * len(self.padding):\n",
    "            s += ', padding={padding}'\n",
    "        if self.dilation != (1,) * len(self.dilation):\n",
    "            s += ', dilation={dilation}'\n",
    "        if self.output_padding != (0,) * len(self.output_padding):\n",
    "            s += ', output_padding={output_padding}'\n",
    "        if self.groups != 1:\n",
    "            s += ', groups={groups}'\n",
    "        if self.bias is None:\n",
    "            s += ', bias=False'\n",
    "        if self.padding_mode != 'zeros':\n",
    "            s += ', padding_mode={padding_mode}'\n",
    "        return s.format(**self.__dict__)\n",
    "\n",
    "    def __setstate__(self, state):\n",
    "        super(_ConvNd, self).__setstate__(state)\n",
    "        if not hasattr(self, 'padding_mode'):\n",
    "            self.padding_mode = 'zeros'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b250464-b960-4a11-bdb9-98a3e731964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class BinarizeKernel(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, weight: Tensor, H: float=1., deterministic: bool=True):\n",
    "        ...\n",
    "        \n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output: Tensor):\n",
    "        ...\n",
    "\n",
    "class BinaryConv2D(_BinaryConvNd):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int,\n",
    "        out_channels: int,\n",
    "        kernel_size: _size_2_t,\n",
    "        stride: _size_2_t = 1,\n",
    "        padding: _size_2_t = 0,\n",
    "        dilation: _size_2_t = 1,\n",
    "        groups: int = 1,\n",
    "        bias: bool = True,\n",
    "        padding_mode: str = 'zeros'  # TODO: refine this type\n",
    "    ):\n",
    "\n",
    "        kernel_size_ = torch.nn.modules.utils._pair(kernel_size)\n",
    "        stride_ = torch.nn.modules.utils._pair(stride)\n",
    "        padding_ = torch.nn.modules.utils._pair(padding)\n",
    "        dilation_ = torch.nn.modules.utils._pair(dilation)\n",
    "        super(Conv2d, self).__init__(\n",
    "            in_channels, out_channels, kernel_size_, stride_, padding_, dilation_,\n",
    "            False, _pair(0), groups, bias, padding_mode)\n",
    "\n",
    "    def _conv_forward(self, input: Tensor, weight: Tensor, bias: Optional[Tensor]):\n",
    "        if self.padding_mode != 'zeros':\n",
    "            return torch.nn.functional.conv2d(F.pad(input, self._reversed_padding_repeated_twice, mode=self.padding_mode),\n",
    "                            weight, bias, self.stride,\n",
    "                            _pair(0), self.dilation, self.groups)\n",
    "        return F.conv2d(input, weight, bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "    def forward(self, input: Tensor) -> Tensor:\n",
    "        return self._conv_forward(input, self.weight, self.bias)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
